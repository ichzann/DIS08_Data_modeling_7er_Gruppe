{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f89aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c1332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten von GitHub und bereite vor...\n",
      "OK: Chemnitz_blaulicht_scrape_2025-12-07.csv geladen.\n",
      "OK: Dortmund_blaulicht_scrape_2025-12-07.csv geladen.\n",
      "OK: Erfurt_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "OK: Nuernberg_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "OK: Saarbruecken_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "FEHLER bei München_blaulicht_scrape_2025-12-18.csv: 'ascii' codec can't encode character '\\xfc' in position 80: ordinal not in range(128)\n",
      "\n",
      "21223 Dokumente insgesamt. TF-IDF Analyse\n",
      "\n",
      "--- Analyse-Ergebnis ---\n",
      "           Stadt  Jahr  Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  Frequenz_Prozent  Diff_Score  Diff_Frequenz\n",
      "0       Chemnitz  2018                1                   0               0.0000            0.0000         NaN            NaN\n",
      "1       Chemnitz  2019               15                   0               0.0000            0.0000      0.0000         0.0000\n",
      "2       Chemnitz  2020               56                   2               0.0045            3.5714      0.0045         3.5714\n",
      "3       Chemnitz  2021               62                   0               0.0000            0.0000     -0.0045        -3.5714\n",
      "4       Chemnitz  2022               90                   0               0.0000            0.0000      0.0000         0.0000\n",
      "5       Chemnitz  2023              141                   3               0.0024            2.1277      0.0024         2.1277\n",
      "6       Chemnitz  2024               80                   3               0.0037            3.7500      0.0014         1.6223\n",
      "7       Chemnitz  2025              242                   4               0.0021            1.6529     -0.0016        -2.0971\n",
      "8       Dortmund  2021               86                   3               0.0035            3.4884         NaN            NaN\n",
      "9       Dortmund  2022             2381                  94               0.0051            3.9479      0.0016         0.4595\n",
      "10      Dortmund  2023             2299                 118               0.0066            5.1327      0.0015         1.1847\n",
      "11      Dortmund  2024             2223                  88               0.0055            3.9586     -0.0011        -1.1741\n",
      "12      Dortmund  2025             3811                  52               0.0020            1.3645     -0.0035        -2.5941\n",
      "13        Erfurt  2018                3                   0               0.0000            0.0000         NaN            NaN\n",
      "14        Erfurt  2019               38                   0               0.0000            0.0000      0.0000         0.0000\n",
      "15        Erfurt  2020              112                   6               0.0113            5.3571      0.0113         5.3571\n",
      "16        Erfurt  2021              134                   2               0.0016            1.4925     -0.0096        -3.8646\n",
      "17        Erfurt  2022              137                   3               0.0022            2.1898      0.0005         0.6972\n",
      "18        Erfurt  2023              354                  16               0.0066            4.5198      0.0044         2.3300\n",
      "19        Erfurt  2024             1752                  28               0.0019            1.5982     -0.0047        -2.9216\n",
      "20        Erfurt  2025             2470                  25               0.0016            1.0121     -0.0004        -0.5860\n",
      "21     Nuernberg  2016                2                   0               0.0000            0.0000         NaN            NaN\n",
      "22     Nuernberg  2017                3                   0               0.0000            0.0000      0.0000         0.0000\n",
      "23     Nuernberg  2018                3                   0               0.0000            0.0000      0.0000         0.0000\n",
      "24     Nuernberg  2019               21                   0               0.0000            0.0000      0.0000         0.0000\n",
      "25     Nuernberg  2020              130                   3               0.0037            2.3077      0.0037         2.3077\n",
      "26     Nuernberg  2021               84                   2               0.0008            2.3810     -0.0029         0.0733\n",
      "27     Nuernberg  2022              112                   3               0.0047            2.6786      0.0040         0.2976\n",
      "28     Nuernberg  2023              209                   6               0.0037            2.8708     -0.0011         0.1922\n",
      "29     Nuernberg  2024              981                  13               0.0014            1.3252     -0.0023        -1.5456\n",
      "30     Nuernberg  2025             1320                  10               0.0013            0.7576     -0.0001        -0.5676\n",
      "31  Saarbruecken  2015                1                   1               0.1536          100.0000         NaN            NaN\n",
      "32  Saarbruecken  2016                8                   0               0.0000            0.0000     -0.1536      -100.0000\n",
      "33  Saarbruecken  2017                6                   1               0.0185           16.6667      0.0185        16.6667\n",
      "34  Saarbruecken  2018               18                   1               0.0021            5.5556     -0.0164       -11.1111\n",
      "35  Saarbruecken  2019               53                   3               0.0033            5.6604      0.0012         0.1048\n",
      "36  Saarbruecken  2020               81                   3               0.0032            3.7037     -0.0001        -1.9567\n",
      "37  Saarbruecken  2021              115                   3               0.0041            2.6087      0.0010        -1.0950\n",
      "38  Saarbruecken  2022               98                   2               0.0024            2.0408     -0.0017        -0.5679\n",
      "39  Saarbruecken  2023              174                   8               0.0045            4.5977      0.0021         2.5569\n",
      "40  Saarbruecken  2024              488                   3               0.0004            0.6148     -0.0041        -3.9829\n",
      "41  Saarbruecken  2025              829                   2               0.0002            0.2413     -0.0002        -0.3735\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zusammenfassungg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Speichern\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrogen_analyse_github_daten.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 134\u001b[0m     zusammenfassungg\u001b[38;5;241m.\u001b[39mto_csv(output_filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDatei erfolgreich gespeichert: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'zusammenfassungg' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- KONFIGURATION: DATENQUELLEN (GITHUB) ---\n",
    "base_url = \"https://raw.githubusercontent.com/ichzann/DIS08_Data_modeling_7er_Gruppe/main/Daten_sets/blaulicht_scraping/\"\n",
    "#base_url = \"https://github.com/ichzann/DIS08_Data_modeling_7er_Gruppe/tree/final_cleanUp/Data/raw/blaulicht_scraping/\"\n",
    "# Liste der Dateien im Repo \n",
    "folders_csv_in_repo = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"München_blaulicht_scrape_2025-12-18.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Daten von GitHub und bereite vor...\")\n",
    "\n",
    "# --- SCHRITT 1: DATEN LADEN (Ihsan teil) ---\n",
    "for file_name in folders_csv_in_repo:\n",
    "    # URL zusammenbauen\n",
    "    url = f\"{base_url}{file_name}\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Pandas kann CSVs direkt von URLs lesen\n",
    "        df = pd.read_csv(url, on_bad_lines='skip') \n",
    "        \n",
    "        # Spalten bereinigen\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        \n",
    "        # 1. Text kombinieren (Title + Abstract)\n",
    "        # Wir prüfen sicherheitshalber, welche Spalten da sind\n",
    "        if 'title' in df.columns and 'abstract' in df.columns:\n",
    "            df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "        else:\n",
    "            # Fallback: Alles verbinden, falls Spaltennamen anders sind\n",
    "            df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "        \n",
    "        # 2. Stadt aus Dateinamen extrahieren\n",
    "        # Split am Unterstrich (z.B. \"Chemnitz_...\")\n",
    "        stadt_name = file_name.split('_')[0]\n",
    "        \n",
    "        # 3. Jahr aus Datum extrahieren\n",
    "        # Wir nutzen hier die robuste Regex-Methode, da sie Format-Unabhängig ist\n",
    "        if 'datum' in df.columns:\n",
    "            df['jahr'] = df['datum'].astype(str).str.extract(r'(\\d{4})')\n",
    "        else:\n",
    "            df['jahr'] = 'Unbekannt'\n",
    "        \n",
    "        # Daten sammeln für die Analyse\n",
    "        # Wir iterieren durch den DataFrame und speichern Text + Metadaten\n",
    "        for text, jahr in zip(df['text'], df['jahr']):\n",
    "            all_docs.append(text)\n",
    "            doc_metadata.append({\n",
    "                'Stadt': stadt_name, \n",
    "                'Jahr': jahr,\n",
    "                'Original_Datei': file_name\n",
    "            })\n",
    "            \n",
    "        print(f\"OK: {file_name} geladen.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER bei {file_name}: {e}\")\n",
    "\n",
    "# --- SCHRITT 2: ANALYSE (TF-IDF) ---\n",
    "if not all_docs:\n",
    "    print(\"Keine Datengeladen.\")\n",
    "else:\n",
    "    print(f\"\\n{len(all_docs)} Dokumente insgesamt. TF-IDF Analyse\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    #Keyword-Liste\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    \n",
    "    # Indizes der Keywords im Vokabular finden\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        # Summe der Scores berechnen\n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse verknüpfen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Jahr': meta['Jahr'],\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # Ungültige Jahre entfernen\n",
    "        ergebnis_df = ergebnis_df.dropna(subset=['Jahr'])\n",
    "        \n",
    "        # --- SCHRITT 3: AGGREGATION & DIFFERENZEN ---\n",
    "        \n",
    "        # Gruppieren nach Stadt und Jahr\n",
    "        zusammenfassung = ergebnis_df.groupby(['Stadt', 'Jahr']).agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), \n",
    "            Durchschnitts_Score=('Score', 'mean')                       ####Raus score nicht nötig \n",
    "        ).reset_index()\n",
    "        \n",
    "        # Frequenz berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        #Sortieren (Stadt -> Jahr), damit die Differenzberechnung stimmt\n",
    "        zusammenfassung = zusammenfassung.sort_values(by=['Stadt', 'Jahr'])\n",
    "\n",
    "        # Differenzen berechnen Veränderung zum Vorjahr innerhalb der gleichen Stadt\n",
    "        zusammenfassung['Diff_Score'] = zusammenfassung.groupby('Stadt')['Durchschnitts_Score'].diff()      ####Raus score nicht nötig \n",
    "        zusammenfassung['Diff_Frequenz'] = zusammenfassung.groupby('Stadt')['Frequenz_Prozent'].diff()\n",
    "\n",
    "        # Runden\n",
    "        zusammenfassung = zusammenfassung.round(4)\n",
    "        \n",
    "        # Ausgabe im Terminal\n",
    "        print(\"\\n--- Analyse-Ergebnis ---\")\n",
    "        print(zusammenfassung.to_string()) \n",
    "        \n",
    "        # Speichern\n",
    "        output_filename = 'drogen_analyse_github_daten.csv'\n",
    "        zusammenfassungg.to_csv(output_filename, index=False, sep=';', decimal=',')\n",
    "        print(f\"\\nDatei erfolgreich gespeichert: {output_filename}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Keine der Suchbegriffe im Textkorpus gefunden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
