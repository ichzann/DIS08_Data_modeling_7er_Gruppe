{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578171df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Dateien und bereite Daten vor...\n",
      "DATEI NICHT GEFUNDEN: ../Data/raw/blaulicht_scraping/Saarbruecken_blaulicht_scrape_2025-12-09-2.csv - Pfad prüfen!\n",
      "19352 Dokumente geladen. Berechne TF-IDF...\n",
      "\n",
      "--- Relevanz-Vergleich der Städte ---\n",
      "           Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  \\\n",
      "Stadt                                                                 \n",
      "Dortmund             10800                 355               0.0044   \n",
      "Chemnitz               687                  12               0.0020   \n",
      "Erfurt                5000                  80               0.0023   \n",
      "Nuernberg             2865                  37               0.0018   \n",
      "\n",
      "           Frequenz_Prozent  \n",
      "Stadt                        \n",
      "Dortmund             3.2870  \n",
      "Chemnitz             1.7467  \n",
      "Erfurt               1.6000  \n",
      "Nuernberg            1.2914  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pfad_zu_dateien = \"../Data/raw/blaulicht_scraping/\" \n",
    "\n",
    "\n",
    "dateien = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09-2.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Dateien und bereite Daten vor...\")\n",
    "\n",
    "for dateiname in dateien:\n",
    "    voller_pfad = os.path.join(pfad_zu_dateien, dateiname)\n",
    "    \n",
    "    if os.path.exists(voller_pfad):\n",
    "        try:\n",
    "            # Daten laden\n",
    "            df = pd.read_csv(voller_pfad, on_bad_lines='skip')\n",
    "            df.columns = [c.lower() for c in df.columns] # Alles kleinschreiben\n",
    "            \n",
    "            # Text kombinieren\n",
    "            if 'title' in df.columns and 'abstract' in df.columns:\n",
    "                df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "            \n",
    "            # Stadt aus Dateinamen extrahieren (alles vor dem ersten Unterstrich)\n",
    "            stadt_name = dateiname.split('_')[0]\n",
    "            \n",
    "            # Speichern für TF-IDF\n",
    "            for idx, text in enumerate(df['text']):\n",
    "                all_docs.append(text)\n",
    "                doc_metadata.append({'Stadt': stadt_name, 'Original_Datei': dateiname})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen von {dateiname}: {e}\")\n",
    "    else:\n",
    "        print(f\"DATEI NICHT GEFUNDEN: {voller_pfad} - Pfad prüfen!\")\n",
    "\n",
    "# Wenn keine Dokumente geladen wurden, abbrechen\n",
    "if not all_docs:\n",
    "    print(\"Keine Daten geladen. Bitte Dateipfade überprüfen.\")\n",
    "else:\n",
    "    print(f\"{len(all_docs)} Dokumente geladen. Berechne TF-IDF...\")\n",
    "\n",
    "    # TF-IDF Berechnung\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Indizes für Keywords finden\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        \n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse zusammenstellen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # AGGREGATION: Zusammenfassung pro Stadt erstellen\n",
    "        zusammenfassung = ergebnis_df.groupby('Stadt').agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), # Zählt Scores größer 0\n",
    "            Durchschnitts_Score=('Score', 'mean')\n",
    "        )\n",
    "        \n",
    "        # Frequenz in Prozent berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        # Sortieren nach Frequenz (Beste zuerst)\n",
    "        zusammenfassung = zusammenfassung.sort_values(by='Frequenz_Prozent', ascending=False)\n",
    "        \n",
    "        print(\"\\n--- Relevanz-Vergleich der Städte ---\")\n",
    "        print(zusammenfassung.round(4)) \n",
    "        \n",
    "    else:\n",
    "        print(\"Die Suchbegriffe 'Drogen' oder 'Kokain' nicht gefunden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574c1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Dateien und bereite Daten vor...\n",
      "DATEI NICHT GEFUNDEN: ../Data/raw/blaulicht_scraping/Saarbruecken_blaulicht_scrape_2025-12-09-2.csv - Pfad prüfen!\n",
      "DATEI NICHT GEFUNDEN: ../Data/raw/blaulicht_scraping/München_blaulicht_scrape_2025-12-18.csv - Pfad prüfen!\n",
      "19352 Dokumente geladen. Berechne TF-IDF...\n",
      "\n",
      "--- Relevanz-Vergleich der Städte nach Jahren ---\n",
      "        Stadt  Jahr  Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  Frequenz_Prozent\n",
      "0    Chemnitz  2018                1                   0               0.0000            0.0000\n",
      "1    Chemnitz  2019               15                   0               0.0000            0.0000\n",
      "2    Chemnitz  2020               56                   2               0.0044            3.5714\n",
      "3    Chemnitz  2021               62                   0               0.0000            0.0000\n",
      "4    Chemnitz  2022               90                   0               0.0000            0.0000\n",
      "5    Chemnitz  2023              141                   3               0.0024            2.1277\n",
      "6    Chemnitz  2024               80                   3               0.0037            3.7500\n",
      "7    Chemnitz  2025              242                   4               0.0021            1.6529\n",
      "8    Dortmund  2021               86                   3               0.0034            3.4884\n",
      "9    Dortmund  2022             2381                  94               0.0050            3.9479\n",
      "10   Dortmund  2023             2299                 118               0.0065            5.1327\n",
      "11   Dortmund  2024             2223                  88               0.0055            3.9586\n",
      "12   Dortmund  2025             3811                  52               0.0020            1.3645\n",
      "13     Erfurt  2018                3                   0               0.0000            0.0000\n",
      "14     Erfurt  2019               38                   0               0.0000            0.0000\n",
      "15     Erfurt  2020              112                   6               0.0112            5.3571\n",
      "16     Erfurt  2021              134                   2               0.0016            1.4925\n",
      "17     Erfurt  2022              137                   3               0.0021            2.1898\n",
      "18     Erfurt  2023              354                  16               0.0066            4.5198\n",
      "19     Erfurt  2024             1752                  28               0.0019            1.5982\n",
      "20     Erfurt  2025             2470                  25               0.0016            1.0121\n",
      "21  Nuernberg  2016                2                   0               0.0000            0.0000\n",
      "22  Nuernberg  2017                3                   0               0.0000            0.0000\n",
      "23  Nuernberg  2018                3                   0               0.0000            0.0000\n",
      "24  Nuernberg  2019               21                   0               0.0000            0.0000\n",
      "25  Nuernberg  2020              130                   3               0.0037            2.3077\n",
      "26  Nuernberg  2021               84                   2               0.0007            2.3810\n",
      "27  Nuernberg  2022              112                   3               0.0048            2.6786\n",
      "28  Nuernberg  2023              209                   6               0.0037            2.8708\n",
      "29  Nuernberg  2024              981                  13               0.0014            1.3252\n",
      "30  Nuernberg  2025             1320                  10               0.0013            0.7576\n",
      "Datei wurde erfolgreich gespeichert!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import re # Wichtig für das Auslesen der Jahreszahl\n",
    "\n",
    "# Ihr Pfad\n",
    "pfad_zu_dateien = \"../Data/raw/blaulicht_scraping/\" \n",
    "\n",
    "dateien = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09-2.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"München_blaulicht_scrape_2025-12-18.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Dateien und bereite Daten vor...\")\n",
    "\n",
    "for dateiname in dateien:\n",
    "    voller_pfad = os.path.join(pfad_zu_dateien, dateiname)\n",
    "    \n",
    "    # Prüfen, ob die Datei existiert\n",
    "    if os.path.exists(voller_pfad):\n",
    "        try:\n",
    "            # Daten laden\n",
    "            df = pd.read_csv(voller_pfad, on_bad_lines='skip')\n",
    "            df.columns = [c.lower() for c in df.columns] # Alles kleinschreiben\n",
    "            \n",
    "            # 1. Text kombinieren\n",
    "            if 'title' in df.columns and 'abstract' in df.columns:\n",
    "                df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "            \n",
    "            # 2. Stadt aus Dateinamen extrahieren\n",
    "            stadt_name = dateiname.split('_')[0]\n",
    "            \n",
    "            # 3. Jahr aus Datum extrahieren (NEU)\n",
    "            # Wir suchen nach 4 aufeinanderfolgenden Ziffern (z.B. \"2023\") in der Spalte 'datum'\n",
    "            if 'datum' in df.columns:\n",
    "                df['jahr'] = df['datum'].astype(str).str.extract(r'(\\d{4})')\n",
    "            else:\n",
    "                df['jahr'] = 'Unbekannt'\n",
    "            \n",
    "            # Speichern für TF-IDF (Text + Metadaten pro Zeile)\n",
    "            # Wir nutzen zip(), um Text und Jahr gleichzeitig durchzugehen\n",
    "            for text, jahr in zip(df['text'], df['jahr']):\n",
    "                all_docs.append(text)\n",
    "                doc_metadata.append({\n",
    "                    'Stadt': stadt_name, \n",
    "                    'Jahr': jahr,\n",
    "                    'Original_Datei': dateiname\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen von {dateiname}: {e}\")\n",
    "    else:\n",
    "        print(f\"DATEI NICHT GEFUNDEN: {voller_pfad} - Pfad prüfen!\")\n",
    "\n",
    "# Wenn keine Dokumente geladen wurden, abbrechen\n",
    "if not all_docs:\n",
    "    print(\"Keine Daten geladen. Bitte Dateipfade überprüfen.\")\n",
    "else:\n",
    "    print(f\"{len(all_docs)} Dokumente geladen. Berechne TF-IDF...\")\n",
    "\n",
    "    # TF-IDF Berechnung\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Ihre erweiterte Liste\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    \n",
    "    # Indizes finden\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        # Summe der Scores für die Suchbegriffe\n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse zusammenstellen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Jahr': meta['Jahr'], # Das Jahr muss hier mit rein\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # Leere Jahre (NaN) entfernen, falls vorhanden\n",
    "        ergebnis_df = ergebnis_df.dropna(subset=['Jahr'])\n",
    "        \n",
    "        # AGGREGATION: Jetzt gruppieren wir nach Stadt UND Jahr\n",
    "        zusammenfassung = ergebnis_df.groupby(['Stadt', 'Jahr']).agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), \n",
    "            Durchschnitts_Score=('Score', 'mean')\n",
    "        ).reset_index() # reset_index macht aus dem Gruppen-Index wieder normale Spalten\n",
    "        \n",
    "        # Frequenz in Prozent berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        zusammenfassung = zusammenfassung.round(4)\n",
    "        \n",
    "        # Sortieren: Zuerst nach Stadt, dann nach Jahr (chronologisch)\n",
    "        zusammenfassung = zusammenfassung.sort_values(by=['Stadt', 'Jahr'])\n",
    "        \n",
    "        print(\"\\n--- Relevanz-Vergleich der Städte nach Jahren ---\")\n",
    "        # to_string() sorgt dafür, dass alle Zeilen angezeigt werden\n",
    "        print(zusammenfassung.to_string()) \n",
    "        \n",
    "    else:\n",
    "        print(\"Keine der Suchbegriffe im Textkorpus gefunden.\")\n",
    "\n",
    "    zusammenfassung.to_csv('drogen_analyse_jahresvergleich.csv', index=False, sep=';', decimal=',')\n",
    "\n",
    "print(\"Datei wurde erfolgreich gespeichert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
