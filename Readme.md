# üß™ Analyse der Korrelation zwischen Abwasser-Drogenr√ºckst√§nden und Polizeiberichten

![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)
![Status](https://img.shields.io/badge/Status-In_Progress-yellow.svg)

> **Dokumentation:** [Projekt-Report lesen](./ProjectReport.md)  
> **Planung:** [Roadmap ansehen](./Roadmap.md)
[Unser Trello Board](assets/trello.png)
> **Lessons Learned:** [Lessons Learned ansehen](Lessons_learned.md)

Dieses Repository enth√§lt die Forschungsarbeit der **Gruppe 4** zur statistischen Beziehung zwischen chemisch nachgewiesenem Drogenkonsum und der √∂ffentlichen Berichterstattung √ºber drogenspezifische Delikte.

---

## üéØ Projektziel

Wir stellen objektive Messwerte aus Kl√§ranlagen den quantitativen Daten aus dem **Blaulichtreport** (Presseportal) gegen√ºber.

* **Forschungsfrage:**  
  Korreliert die Menge der Drogenr√ºckst√§nde im Abwasser mit der H√§ufigkeit polizeilicher Meldungen in deutschen Gro√üst√§dten?
* **Untersuchte St√§dte:**  
  Chemnitz, Dortmund, Erfurt, M√ºnchen, N√ºrnberg, Saarbr√ºcken

---

## üìù Projektbeschreibung

Ziel dieses Projekts ist es zu untersuchen, ob eine messbare **Korrelation zwischen konsumierten Drogen** (basierend auf Abwasseranalysedaten der **EUDA**, ehemals EMCDDA) und der **Anzahl polizeilicher Meldungen** in den jeweiligen St√§dten besteht.

Hierbei werden objektive Messwerte aus Wasserwerken systematisch den quantitativen Daten des Presseportals gegen√ºbergestellt.

---

## üóÇ Projektstruktur

```text
DIS08_Data_modeling/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ scraping/
‚îÇ       ‚îú‚îÄ‚îÄ blaulicht_scaper.py   # Haupt-Scraper (Multiprocessing)
‚îÇ       ‚îú‚îÄ‚îÄ get_proxies.py        # Proxy-Rotation
‚îÇ   ‚îî‚îÄ‚îÄ config.ini                # Zentrale Konfiguration
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ analyse.ipynb             # Deskriptive Statistik & Visualisierung
‚îÇ   ‚îú‚îÄ‚îÄ Hypothesentest.ipynb      # Spearman-Korrelation & Signifikanztests
‚îÇ   ‚îî‚îÄ‚îÄ retrieval.ipynb           # TF-IDF & IR-Analyse
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Rohdaten
‚îÇ   ‚îî‚îÄ‚îÄ processed/                # Bereinigte CSV-Dateien
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üõ† Methodik & Features

Das Projekt deckt den gesamten **Data-Science-Zyklus** ab ‚Äì von der Datenerhebung bis zur statistischen Auswertung:

### Scraping & Datenerhebung

* Urspr√ºnglich war das Scraping mehrerer lokaler Nachrichtenquellen geplant.
* Zur besseren **Skalierbarkeit** und **Wartbarkeit** wurde der Fokus auf den zentralen **Blaulichtreport** gelegt.
* Ergebnis ist ein spezialisierter Scraper, der mehrere St√§dte effizient aggregiert, ohne quellspezifische Logik zu ben√∂tigen.

### Data Cleaning & Vorbereitung

* Bereinigung und Vereinheitlichung der Rohdaten.
* Zusammenf√ºhrung in einen konsolidierten Datensatz mit den Variablen:

  * Stadt
  * Jahr
  * Drogentyp
  * Berichth√§ufigkeit

### Information Retrieval (IR)

* Einsatz von IR-Techniken zur Quantifizierung relevanter Polizeiberichte pro Stadt und Jahr.
* Ziel: Abbildung der √∂ffentlichen Wahrnehmung bzw. polizeilichen Dokumentation von Drogendelikten.
[H√§ufigkeit der Schlagw√∂rter](assets/drogen_wordcloud.jpeg)

### Statistische Auswertung

* Untersuchung der Korrelation zwischen:

  * **Milligramm pro Tag (daily mean)** aus Abwasseranalysen
  * **Trefferquote** aus dem Information Retrieval
* Einsatz von **Spearman-Rangkorrelation** und Signifikanztests.

---

## Voraussetzungen

* **Python:** Version 3.12 oder h√∂her
* **Paketmanager:** `pip`

---

## üõ† Installation & Setup

### 1Ô∏è‚É£ Repository klonen

```bash
git clone https://github.com/ichzann/DIS08_Data_modeling.git
cd DIS08_Data_modeling
```

### 2Ô∏è‚É£ Virtuelle Umgebung erstellen (empfohlen)

**Windows**

```bash
python -m venv venv
.\venv\Scripts\activate
```

**macOS / Linux**

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3Ô∏è‚É£ Abh√§ngigkeiten installieren

```bash
pip install -r requirements.txt
```

---

## Konfiguration & Nutzung

### St√§dte anpassen

In der Datei `config.ini` k√∂nnen die zu analysierenden St√§dte festgelegt werden:

```ini
[ScrapingEinstellungen]
staedte = Chemnitz, Dortmund, M√ºnchen
tempo = 10
```

### Scraper starten

```bash
python src/scraping/blaulicht_scaper.py
```

### Analysen durchf√ºhren

```bash
jupyter notebook
```

Beispiele:

* `analyse.ipynb` ‚Äì Visualisierungen & deskriptive Statistik
* `Hypothesentest.ipynb` ‚Äì Korrelationen & Signifikanztests

---

## Ergebnisse (Auszug)

* Erste **Spearman-Hypothesentests** zeigen f√ºr den Gesamtdatensatz keinen signifikanten Zusammenhang (p-Wert > 0.05).
* Einzelne St√§dte wie **Chemnitz** und **Erfurt** weisen jedoch starke Korrelationen auf und werden weiter untersucht.

---


