{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a334d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Dateien und bereite Daten vor...\n",
      "21223 Dokumente geladen. Berechne TF-IDF...\n",
      "\n",
      "--- Relevanz-Vergleich der Städte ---\n",
      "              Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  \\\n",
      "Stadt                                                                    \n",
      "Dortmund                10800                 355               0.0044   \n",
      "Chemnitz                  687                  12               0.0020   \n",
      "Erfurt                   5000                  80               0.0023   \n",
      "Saarbruecken             1871                  27               0.0014   \n",
      "Nuernberg                2865                  37               0.0018   \n",
      "\n",
      "              Frequenz_Prozent  \n",
      "Stadt                           \n",
      "Dortmund                3.2870  \n",
      "Chemnitz                1.7467  \n",
      "Erfurt                  1.6000  \n",
      "Saarbruecken            1.4431  \n",
      "Nuernberg               1.2914  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pfad_zu_dateien = \"/Users/zen/Documents/Data and information/Semester 3/Retrieval/\" \n",
    "\n",
    "\n",
    "dateien = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09-2.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Dateien und bereite Daten vor...\")\n",
    "\n",
    "for dateiname in dateien:\n",
    "    voller_pfad = os.path.join(pfad_zu_dateien, dateiname)\n",
    "    \n",
    "    if os.path.exists(voller_pfad):\n",
    "        try:\n",
    "            # Daten laden\n",
    "            df = pd.read_csv(voller_pfad, on_bad_lines='skip')\n",
    "            df.columns = [c.lower() for c in df.columns] # Alles kleinschreiben\n",
    "            \n",
    "            # Text kombinieren\n",
    "            if 'title' in df.columns and 'abstract' in df.columns:\n",
    "                df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "            \n",
    "            # Stadt aus Dateinamen extrahieren (alles vor dem ersten Unterstrich)\n",
    "            stadt_name = dateiname.split('_')[0]\n",
    "            \n",
    "            # Speichern für TF-IDF\n",
    "            for idx, text in enumerate(df['text']):\n",
    "                all_docs.append(text)\n",
    "                doc_metadata.append({'Stadt': stadt_name, 'Original_Datei': dateiname})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen von {dateiname}: {e}\")\n",
    "    else:\n",
    "        print(f\"DATEI NICHT GEFUNDEN: {voller_pfad} - Pfad prüfen!\")\n",
    "\n",
    "# Wenn keine Dokumente geladen wurden, abbrechen\n",
    "if not all_docs:\n",
    "    print(\"Keine Daten geladen. Bitte Dateipfade überprüfen.\")\n",
    "else:\n",
    "    print(f\"{len(all_docs)} Dokumente geladen. Berechne TF-IDF...\")\n",
    "\n",
    "    # TF-IDF Berechnung\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Indizes für Keywords finden\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        \n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse zusammenstellen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # AGGREGATION: Zusammenfassung pro Stadt erstellen\n",
    "        zusammenfassung = ergebnis_df.groupby('Stadt').agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), # Zählt Scores größer 0\n",
    "            Durchschnitts_Score=('Score', 'mean')\n",
    "        )\n",
    "        \n",
    "        # Frequenz in Prozent berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        # Sortieren nach Frequenz (Beste zuerst)\n",
    "        zusammenfassung = zusammenfassung.sort_values(by='Frequenz_Prozent', ascending=False)\n",
    "        \n",
    "        print(\"\\n--- Relevanz-Vergleich der Städte ---\")\n",
    "        print(zusammenfassung.round(4)) \n",
    "        \n",
    "    else:\n",
    "        print(\"Die Suchbegriffe 'Drogen' oder 'Kokain' nicht gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddb6f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Dateien und bereite Daten vor...\n",
      "28248 Dokumente geladen. Berechne TF-IDF...\n",
      "\n",
      "--- Relevanz-Vergleich der Städte nach Jahren ---\n",
      "           Stadt  Jahr  Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  Frequenz_Prozent\n",
      "0       Chemnitz  2018                1                   0               0.0000            0.0000\n",
      "1       Chemnitz  2019               15                   0               0.0000            0.0000\n",
      "2       Chemnitz  2020               56                   2               0.0046            3.5714\n",
      "3       Chemnitz  2021               62                   0               0.0000            0.0000\n",
      "4       Chemnitz  2022               90                   0               0.0000            0.0000\n",
      "5       Chemnitz  2023              141                   3               0.0024            2.1277\n",
      "6       Chemnitz  2024               80                   3               0.0038            3.7500\n",
      "7       Chemnitz  2025              242                   4               0.0022            1.6529\n",
      "8       Dortmund  2021               86                   3               0.0035            3.4884\n",
      "9       Dortmund  2022             2381                  94               0.0051            3.9479\n",
      "10      Dortmund  2023             2299                 118               0.0067            5.1327\n",
      "11      Dortmund  2024             2223                  88               0.0055            3.9586\n",
      "12      Dortmund  2025             3811                  52               0.0020            1.3645\n",
      "13        Erfurt  2018                3                   0               0.0000            0.0000\n",
      "14        Erfurt  2019               38                   0               0.0000            0.0000\n",
      "15        Erfurt  2020              112                   6               0.0116            5.3571\n",
      "16        Erfurt  2021              134                   2               0.0017            1.4925\n",
      "17        Erfurt  2022              137                   3               0.0022            2.1898\n",
      "18        Erfurt  2023              354                  16               0.0066            4.5198\n",
      "19        Erfurt  2024             1752                  28               0.0020            1.5982\n",
      "20        Erfurt  2025             2470                  25               0.0016            1.0121\n",
      "21      München  2016                4                   1               0.0193           25.0000\n",
      "22      München  2017               10                   1               0.0096           10.0000\n",
      "23      München  2018               31                   2               0.0080            6.4516\n",
      "24      München  2019              126                   5               0.0059            3.9683\n",
      "25      München  2020              606                  16               0.0030            2.6403\n",
      "26      München  2021              632                  21               0.0040            3.3228\n",
      "27      München  2022              762                  21               0.0031            2.7559\n",
      "28      München  2023              919                  61               0.0063            6.6376\n",
      "29      München  2024             1488                  50               0.0035            3.3602\n",
      "30      München  2025             2447                  44               0.0022            1.7981\n",
      "31     Nuernberg  2016                2                   0               0.0000            0.0000\n",
      "32     Nuernberg  2017                3                   0               0.0000            0.0000\n",
      "33     Nuernberg  2018                3                   0               0.0000            0.0000\n",
      "34     Nuernberg  2019               21                   0               0.0000            0.0000\n",
      "35     Nuernberg  2020              130                   3               0.0036            2.3077\n",
      "36     Nuernberg  2021               84                   2               0.0008            2.3810\n",
      "37     Nuernberg  2022              112                   3               0.0047            2.6786\n",
      "38     Nuernberg  2023              209                   6               0.0038            2.8708\n",
      "39     Nuernberg  2024              981                  13               0.0015            1.3252\n",
      "40     Nuernberg  2025             1320                  10               0.0014            0.7576\n",
      "41  Saarbruecken  2015                1                   1               0.1488          100.0000\n",
      "42  Saarbruecken  2016                8                   0               0.0000            0.0000\n",
      "43  Saarbruecken  2017                6                   1               0.0182           16.6667\n",
      "44  Saarbruecken  2018               18                   1               0.0020            5.5556\n",
      "45  Saarbruecken  2019               53                   3               0.0033            5.6604\n",
      "46  Saarbruecken  2020               81                   3               0.0031            3.7037\n",
      "47  Saarbruecken  2021              115                   3               0.0042            2.6087\n",
      "48  Saarbruecken  2022               98                   2               0.0024            2.0408\n",
      "49  Saarbruecken  2023              174                   8               0.0046            4.5977\n",
      "50  Saarbruecken  2024              488                   3               0.0004            0.6148\n",
      "51  Saarbruecken  2025              829                   2               0.0002            0.2413\n",
      "Datei wurde erfolgreich gespeichert!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import re # Wichtig für das Auslesen der Jahreszahl\n",
    "\n",
    "# Ihr Pfad\n",
    "pfad_zu_dateien = \"/Users/zen/Documents/Data and information/Semester 3/Retrieval/\" \n",
    "\n",
    "dateien = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09-2.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"München_blaulicht_scrape_2025-12-18.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Dateien und bereite Daten vor...\")\n",
    "\n",
    "for dateiname in dateien:\n",
    "    voller_pfad = os.path.join(pfad_zu_dateien, dateiname)\n",
    "    \n",
    "    # Prüfen, ob die Datei existiert\n",
    "    if os.path.exists(voller_pfad):\n",
    "        try:\n",
    "            # Daten laden\n",
    "            df = pd.read_csv(voller_pfad, on_bad_lines='skip')\n",
    "            df.columns = [c.lower() for c in df.columns] # Alles kleinschreiben\n",
    "            \n",
    "            # 1. Text kombinieren\n",
    "            if 'title' in df.columns and 'abstract' in df.columns:\n",
    "                df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "            \n",
    "            # 2. Stadt aus Dateinamen extrahieren\n",
    "            stadt_name = dateiname.split('_')[0]\n",
    "            \n",
    "            # 3. Jahr aus Datum extrahieren (NEU)\n",
    "            # Wir suchen nach 4 aufeinanderfolgenden Ziffern (z.B. \"2023\") in der Spalte 'datum'\n",
    "            if 'datum' in df.columns:\n",
    "                df['jahr'] = df['datum'].astype(str).str.extract(r'(\\d{4})')\n",
    "            else:\n",
    "                df['jahr'] = 'Unbekannt'\n",
    "            \n",
    "            # Speichern für TF-IDF (Text + Metadaten pro Zeile)\n",
    "            # Wir nutzen zip(), um Text und Jahr gleichzeitig durchzugehen\n",
    "            for text, jahr in zip(df['text'], df['jahr']):\n",
    "                all_docs.append(text)\n",
    "                doc_metadata.append({\n",
    "                    'Stadt': stadt_name, \n",
    "                    'Jahr': jahr,\n",
    "                    'Original_Datei': dateiname\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen von {dateiname}: {e}\")\n",
    "    else:\n",
    "        print(f\"DATEI NICHT GEFUNDEN: {voller_pfad} - Pfad prüfen!\")\n",
    "\n",
    "# Wenn keine Dokumente geladen wurden, abbrechen\n",
    "if not all_docs:\n",
    "    print(\"Keine Daten geladen. Bitte Dateipfade überprüfen.\")\n",
    "else:\n",
    "    print(f\"{len(all_docs)} Dokumente geladen. Berechne TF-IDF...\")\n",
    "\n",
    "    # TF-IDF Berechnung\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Ihre erweiterte Liste\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    \n",
    "    # Indizes finden\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        # Summe der Scores für die Suchbegriffe\n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse zusammenstellen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Jahr': meta['Jahr'], # Das Jahr muss hier mit rein\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # Leere Jahre (NaN) entfernen, falls vorhanden\n",
    "        ergebnis_df = ergebnis_df.dropna(subset=['Jahr'])\n",
    "        \n",
    "        # AGGREGATION: Jetzt gruppieren wir nach Stadt UND Jahr\n",
    "        zusammenfassung = ergebnis_df.groupby(['Stadt', 'Jahr']).agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), \n",
    "            Durchschnitts_Score=('Score', 'mean')\n",
    "        ).reset_index() # reset_index macht aus dem Gruppen-Index wieder normale Spalten\n",
    "        \n",
    "        # Frequenz in Prozent berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        zusammenfassung = zusammenfassung.round(4)\n",
    "        \n",
    "        # Sortieren: Zuerst nach Stadt, dann nach Jahr (chronologisch)\n",
    "        zusammenfassung = zusammenfassung.sort_values(by=['Stadt', 'Jahr'])\n",
    "        \n",
    "        print(\"\\n--- Relevanz-Vergleich der Städte nach Jahren ---\")\n",
    "        # to_string() sorgt dafür, dass alle Zeilen angezeigt werden\n",
    "        print(zusammenfassung.to_string()) \n",
    "        \n",
    "    else:\n",
    "        print(\"Keine der Suchbegriffe im Textkorpus gefunden.\")\n",
    "\n",
    "    zusammenfassung.to_csv('drogen_analyse_jahresvergleich.csv', index=False, sep=';', decimal=',')\n",
    "\n",
    "print(\"Datei wurde erfolgreich gespeichert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f89aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten von GitHub und bereite vor...\n",
      "OK: Chemnitz_blaulicht_scrape_2025-12-07.csv geladen.\n",
      "OK: Dortmund_blaulicht_scrape_2025-12-07.csv geladen.\n",
      "OK: Erfurt_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "OK: Nuernberg_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "OK: Saarbruecken_blaulicht_scrape_2025-12-09.csv geladen.\n",
      "FEHLER bei München_blaulicht_scrape_2025-12-18.csv: 'ascii' codec can't encode character '\\u0308' in position 81: ordinal not in range(128)\n",
      "\n",
      "21223 Dokumente insgesamt. Starte TF-IDF Analyse...\n",
      "\n",
      "--- Analyse-Ergebnis (Auszug) ---\n",
      "           Stadt  Jahr  Gesamt_Berichte  Relevante_Berichte  Durchschnitts_Score  Frequenz_Prozent  Diff_Score  Diff_Frequenz\n",
      "0       Chemnitz  2018                1                   0               0.0000            0.0000         NaN            NaN\n",
      "1       Chemnitz  2019               15                   0               0.0000            0.0000      0.0000         0.0000\n",
      "2       Chemnitz  2020               56                   2               0.0045            3.5714      0.0045         3.5714\n",
      "3       Chemnitz  2021               62                   0               0.0000            0.0000     -0.0045        -3.5714\n",
      "4       Chemnitz  2022               90                   0               0.0000            0.0000      0.0000         0.0000\n",
      "5       Chemnitz  2023              141                   3               0.0024            2.1277      0.0024         2.1277\n",
      "6       Chemnitz  2024               80                   3               0.0037            3.7500      0.0014         1.6223\n",
      "7       Chemnitz  2025              242                   4               0.0021            1.6529     -0.0016        -2.0971\n",
      "8       Dortmund  2021               86                   3               0.0035            3.4884         NaN            NaN\n",
      "9       Dortmund  2022             2381                  94               0.0051            3.9479      0.0016         0.4595\n",
      "10      Dortmund  2023             2299                 118               0.0066            5.1327      0.0015         1.1847\n",
      "11      Dortmund  2024             2223                  88               0.0055            3.9586     -0.0011        -1.1741\n",
      "12      Dortmund  2025             3811                  52               0.0020            1.3645     -0.0035        -2.5941\n",
      "13        Erfurt  2018                3                   0               0.0000            0.0000         NaN            NaN\n",
      "14        Erfurt  2019               38                   0               0.0000            0.0000      0.0000         0.0000\n",
      "15        Erfurt  2020              112                   6               0.0113            5.3571      0.0113         5.3571\n",
      "16        Erfurt  2021              134                   2               0.0016            1.4925     -0.0096        -3.8646\n",
      "17        Erfurt  2022              137                   3               0.0022            2.1898      0.0005         0.6972\n",
      "18        Erfurt  2023              354                  16               0.0066            4.5198      0.0044         2.3300\n",
      "19        Erfurt  2024             1752                  28               0.0019            1.5982     -0.0047        -2.9216\n",
      "20        Erfurt  2025             2470                  25               0.0016            1.0121     -0.0004        -0.5860\n",
      "21     Nuernberg  2016                2                   0               0.0000            0.0000         NaN            NaN\n",
      "22     Nuernberg  2017                3                   0               0.0000            0.0000      0.0000         0.0000\n",
      "23     Nuernberg  2018                3                   0               0.0000            0.0000      0.0000         0.0000\n",
      "24     Nuernberg  2019               21                   0               0.0000            0.0000      0.0000         0.0000\n",
      "25     Nuernberg  2020              130                   3               0.0037            2.3077      0.0037         2.3077\n",
      "26     Nuernberg  2021               84                   2               0.0008            2.3810     -0.0029         0.0733\n",
      "27     Nuernberg  2022              112                   3               0.0047            2.6786      0.0040         0.2976\n",
      "28     Nuernberg  2023              209                   6               0.0037            2.8708     -0.0011         0.1922\n",
      "29     Nuernberg  2024              981                  13               0.0014            1.3252     -0.0023        -1.5456\n",
      "30     Nuernberg  2025             1320                  10               0.0013            0.7576     -0.0001        -0.5676\n",
      "31  Saarbruecken  2015                1                   1               0.1536          100.0000         NaN            NaN\n",
      "32  Saarbruecken  2016                8                   0               0.0000            0.0000     -0.1536      -100.0000\n",
      "33  Saarbruecken  2017                6                   1               0.0185           16.6667      0.0185        16.6667\n",
      "34  Saarbruecken  2018               18                   1               0.0021            5.5556     -0.0164       -11.1111\n",
      "35  Saarbruecken  2019               53                   3               0.0033            5.6604      0.0012         0.1048\n",
      "36  Saarbruecken  2020               81                   3               0.0032            3.7037     -0.0001        -1.9567\n",
      "37  Saarbruecken  2021              115                   3               0.0041            2.6087      0.0010        -1.0950\n",
      "38  Saarbruecken  2022               98                   2               0.0024            2.0408     -0.0017        -0.5679\n",
      "39  Saarbruecken  2023              174                   8               0.0045            4.5977      0.0021         2.5569\n",
      "40  Saarbruecken  2024              488                   3               0.0004            0.6148     -0.0041        -3.9829\n",
      "41  Saarbruecken  2025              829                   2               0.0002            0.2413     -0.0002        -0.3735\n",
      "\n",
      "Datei erfolgreich gespeichert: drogen_analyse_github_daten.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- KONFIGURATION: DATENQUELLEN (GITHUB) ---\n",
    "base_url = \"https://raw.githubusercontent.com/ichzann/DIS08_Data_modeling_7er_Gruppe/main/Daten_sets/blaulicht_scraping/\"\n",
    "\n",
    "# Liste der Dateien im Repo \n",
    "folders_csv_in_repo = [\n",
    "    \"Chemnitz_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Dortmund_blaulicht_scrape_2025-12-07.csv\",\n",
    "    \"Erfurt_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Nuernberg_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"Saarbruecken_blaulicht_scrape_2025-12-09.csv\",\n",
    "    \"München_blaulicht_scrape_2025-12-18.csv\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "doc_metadata = []\n",
    "\n",
    "print(\"Lade Daten von GitHub und bereite vor...\")\n",
    "\n",
    "# --- SCHRITT 1: DATEN LADEN ---\n",
    "for file_name in folders_csv_in_repo:\n",
    "    # URL zusammenbauen\n",
    "    url = f\"{base_url}{file_name}\"\n",
    "    \n",
    "    try:\n",
    "        # Pandas kann CSVs direkt von URLs lesen\n",
    "        # storage_options={'User-Agent': 'Mozilla/5.0'} hilft manchmal bei Zugriffsproblemen, meist geht es aber ohne\n",
    "        df = pd.read_csv(url, on_bad_lines='skip')\n",
    "        \n",
    "        # Spalten bereinigen\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        \n",
    "        # 1. Text kombinieren (Title + Abstract)\n",
    "        # Wir prüfen sicherheitshalber, welche Spalten da sind\n",
    "        if 'title' in df.columns and 'abstract' in df.columns:\n",
    "            df['text'] = df['title'].astype(str) + \" \" + df['abstract'].astype(str)\n",
    "        else:\n",
    "            # Fallback: Alles verbinden, falls Spaltennamen anders sind\n",
    "            df['text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "        \n",
    "        # 2. Stadt aus Dateinamen extrahieren\n",
    "        # Split am Unterstrich (z.B. \"Chemnitz_...\")\n",
    "        stadt_name = file_name.split('_')[0]\n",
    "        \n",
    "        # 3. Jahr aus Datum extrahieren\n",
    "        # Wir nutzen hier die robuste Regex-Methode, da sie Format-Unabhängig ist\n",
    "        if 'datum' in df.columns:\n",
    "            df['jahr'] = df['datum'].astype(str).str.extract(r'(\\d{4})')\n",
    "        else:\n",
    "            df['jahr'] = 'Unbekannt'\n",
    "        \n",
    "        # Daten sammeln für die Analyse\n",
    "        # Wir iterieren durch den DataFrame und speichern Text + Metadaten\n",
    "        for text, jahr in zip(df['text'], df['jahr']):\n",
    "            all_docs.append(text)\n",
    "            doc_metadata.append({\n",
    "                'Stadt': stadt_name, \n",
    "                'Jahr': jahr,\n",
    "                'Original_Datei': file_name\n",
    "            })\n",
    "            \n",
    "        print(f\"OK: {file_name} geladen.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER bei {file_name}: {e}\")\n",
    "\n",
    "# --- SCHRITT 2: ANALYSE (TF-IDF) ---\n",
    "if not all_docs:\n",
    "    print(\"Keine Datengeladen.\")\n",
    "else:\n",
    "    print(f\"\\n{len(all_docs)} Dokumente insgesamt. TF-IDF Analyse\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    #Keyword-Liste\n",
    "    suchbegriffe = ['drogen', 'kokain', 'koks', 'droge', 'mdma', 'methamphetamin', 'methamphetamine']\n",
    "    \n",
    "    # Indizes der Keywords im Vokabular finden\n",
    "    target_indices = [np.where(feature_names == k)[0][0] for k in suchbegriffe if k in feature_names]\n",
    "\n",
    "    if target_indices:\n",
    "        # Summe der Scores berechnen\n",
    "        scores = np.asarray(tfidf_matrix[:, target_indices].sum(axis=1)).flatten()\n",
    "        \n",
    "        # Ergebnisse verknüpfen\n",
    "        ergebnis_liste = []\n",
    "        for i, meta in enumerate(doc_metadata):\n",
    "            ergebnis_liste.append({\n",
    "                'Stadt': meta['Stadt'],\n",
    "                'Jahr': meta['Jahr'],\n",
    "                'Score': scores[i]\n",
    "            })\n",
    "        \n",
    "        ergebnis_df = pd.DataFrame(ergebnis_liste)\n",
    "        \n",
    "        # Ungültige Jahre entfernen\n",
    "        ergebnis_df = ergebnis_df.dropna(subset=['Jahr'])\n",
    "        \n",
    "        # --- SCHRITT 3: AGGREGATION & DIFFERENZEN ---\n",
    "        \n",
    "        # Gruppieren nach Stadt und Jahr\n",
    "        zusammenfassung = ergebnis_df.groupby(['Stadt', 'Jahr']).agg(\n",
    "            Gesamt_Berichte=('Score', 'count'),\n",
    "            Relevante_Berichte=('Score', lambda x: (x > 0).sum()), \n",
    "            Durchschnitts_Score=('Score', 'mean')                       ####Raus score nicht nötig \n",
    "        ).reset_index()\n",
    "        \n",
    "        # Frequenz berechnen\n",
    "        zusammenfassung['Frequenz_Prozent'] = (zusammenfassung['Relevante_Berichte'] / zusammenfassung['Gesamt_Berichte']) * 100\n",
    "        \n",
    "        #Sortieren (Stadt -> Jahr), damit die Differenzberechnung stimmt\n",
    "        zusammenfassung = zusammenfassung.sort_values(by=['Stadt', 'Jahr'])\n",
    "\n",
    "        # Differenzen berechnen Veränderung zum Vorjahr innerhalb der gleichen Stadt\n",
    "        zusammenfassung['Diff_Score'] = zusammenfassung.groupby('Stadt')['Durchschnitts_Score'].diff()      ####Raus score nicht nötig \n",
    "        zusammenfassung['Diff_Frequenz'] = zusammenfassung.groupby('Stadt')['Frequenz_Prozent'].diff()\n",
    "\n",
    "        # Runden\n",
    "        zusammenfassung = zusammenfassung.round(4)\n",
    "        \n",
    "        # Ausgabe im Terminal\n",
    "        print(\"\\n--- Analyse-Ergebnis ---\")\n",
    "        print(zusammenfassung.to_string()) \n",
    "        \n",
    "        # Speichern\n",
    "        output_filename = 'drogen_analyse_github_daten.csv'\n",
    "        zusammenfassung.to_csv(output_filename, index=False, sep=';', decimal=',')\n",
    "        print(f\"\\nDatei erfolgreich gespeichert: {output_filename}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Keine der Suchbegriffe im Textkorpus gefunden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
